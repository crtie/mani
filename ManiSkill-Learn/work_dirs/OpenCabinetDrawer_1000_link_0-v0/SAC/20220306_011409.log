OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:10 - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA GeForce GTX 1650
CUDA_HOME: /usr/local/cuda-11.1/bin
NVCC: 
Num of GPUs: 1
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.9.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.0
OpenCV: 4.5.3
mani_skill_learn: 1.0.0
------------------------------------------------------------

OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:10 - Config:
agent = dict(
    type='SAC',
    batch_size=1024,
    gamma=0.95,
    update_coeff=0.005,
    alpha=0.2,
    target_update_interval=1,
    automatic_alpha_tuning=True,
    alpha_optim_cfg=dict(type='Adam', lr=0.0003),
    policy_cfg=dict(
        type='ContinuousPolicy',
        policy_head_cfg=dict(
            type='GaussianHead', log_sig_min=-20, log_sig_max=2,
            epsilon=1e-06),
        nn_cfg=dict(
            type='LinearMLP',
            norm_cfg=None,
            mlp_spec=['obs_shape', 256, 256, 256, 'action_shape * 2'],
            bias='auto',
            inactivated_output=True,
            linear_init_cfg=dict(type='xavier_init', gain=1, bias=0)),
        optim_cfg=dict(type='Adam', lr=0.0003)),
    value_cfg=dict(
        type='ContinuousValue',
        num_heads=2,
        nn_cfg=dict(
            type='LinearMLP',
            norm_cfg=None,
            bias='auto',
            mlp_spec=['obs_shape + action_shape', 256, 256, 256, 1],
            inactivated_output=True,
            linear_init_cfg=dict(type='xavier_init', gain=1, bias=0)),
        optim_cfg=dict(type='Adam', lr=0.0003)))
log_level = 'INFO'
train_mfrl_cfg = dict(
    on_policy=False,
    total_steps=1000000,
    warm_steps=4000,
    n_eval=200000,
    n_checkpoint=200000,
    n_steps=8,
    n_updates=4)
rollout_cfg = dict(
    type='BatchRollout',
    use_cost=False,
    reward_only=False,
    num_procs=8,
    with_info=False,
    env_cfg=dict(
        type='gym',
        unwrapped=False,
        reward_type='dense',
        env_name='OpenCabinetDrawer_1000_link_0-v0'))
eval_cfg = dict(
    type='BatchEvaluation',
    num=10,
    num_procs=2,
    use_hidden_state=False,
    start_state=None,
    save_traj=True,
    save_video=True,
    use_log=False,
    env_cfg=dict(
        type='gym',
        unwrapped=False,
        reward_type='dense',
        env_name='OpenCabinetDrawer_1000_link_0-v0'))
env_cfg = dict(
    type='gym',
    unwrapped=False,
    reward_type='dense',
    env_name='OpenCabinetDrawer_1000_link_0-v0')
replay_cfg = dict(type='ReplayMemory', capacity=1000000)
work_dir = './work_dirs/OpenCabinetDrawer_1000_link_0-v0/SAC'

OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:10 - Set random seed to 0
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:14 - State shape:75, action shape:Box(-1.0, 1.0, (13,), float32)
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:16 - We do not use distributed training, but we support data parallel in torch
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:16 - SAC(
  (policy): ContinuousPolicy(
    (backbone): LinearMLP(
      (mlp): Sequential(
        (linear0): Linear(in_features=75, out_features=256, bias=True)
        (act0): ReLU()
        (linear1): Linear(in_features=256, out_features=256, bias=True)
        (act1): ReLU()
        (linear2): Linear(in_features=256, out_features=256, bias=True)
        (act2): ReLU()
        (linear3): Linear(in_features=256, out_features=26, bias=True)
      )
    )
    (policy_head): GaussianHead()
  )
  (critic): ContinuousValue(
    (values): ModuleList(
      (0): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
      (1): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
    )
  )
  (target_critic): ContinuousValue(
    (values): ModuleList(
      (0): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
      (1): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
    )
  )
)
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:16 - Rollout state dim: (8, 75), action dim: 8
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:25 - Finish 4000 warm-up steps!
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:37 - 5600/1000000(1%) Passed time:11s ETA:2h4m31s episode_length:200.00 episode_reward:-2687.66 critic_loss:0.52 max_critic_abs_err:2.56 policy_loss:16.28 alpha:0.80 alpha_loss:17.37 q:-23.33 q_target:-23.23 log_pi:-8.81 memory:8.12G gpu_mem_ratio:53.5% gpu_mem:2.14G gpu_mem_this:1.40G gpu_util:37%
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:14:49 - 7200/1000000(1%) Passed time:23s ETA:2h3m36s episode_length:200.00 episode_reward:-2389.38 critic_loss:0.60 max_critic_abs_err:2.79 policy_loss:37.99 alpha:0.65 alpha_loss:13.88 q:-43.78 q_target:-43.65 log_pi:-8.46 memory:8.13G gpu_mem_ratio:53.5% gpu_mem:2.14G gpu_mem_this:1.40G gpu_util:40%
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:15:01 - 8800/1000000(1%) Passed time:36s ETA:2h5m58s episode_length:200.00 episode_reward:-2250.91 critic_loss:0.70 max_critic_abs_err:2.30 policy_loss:58.22 alpha:0.53 alpha_loss:11.20 q:-63.11 q_target:-62.94 log_pi:-8.06 memory:8.13G gpu_mem_ratio:53.5% gpu_mem:2.14G gpu_mem_this:1.40G gpu_util:34%
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:15:15 - 10400/1000000(1%) Passed time:49s ETA:2h9m12s episode_length:200.00 episode_reward:-2172.12 critic_loss:0.97 max_critic_abs_err:3.12 policy_loss:75.47 alpha:0.44 alpha_loss:9.13 q:-79.83 q_target:-79.58 log_pi:-7.69 memory:8.13G gpu_mem_ratio:53.8% gpu_mem:2.15G gpu_mem_this:1.40G gpu_util:36%
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:15:29 - 12000/1000000(1%) Passed time:1m3s ETA:2h12m11s episode_length:200.00 episode_reward:-2141.34 critic_loss:0.94 max_critic_abs_err:2.86 policy_loss:91.29 alpha:0.37 alpha_loss:7.45 q:-94.92 q_target:-94.73 log_pi:-7.22 memory:8.13G gpu_mem_ratio:53.6% gpu_mem:2.14G gpu_mem_this:1.40G gpu_util:36%
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:15:43 - 13600/1000000(1%) Passed time:1m18s ETA:2h14m42s episode_length:200.00 episode_reward:-2118.79 critic_loss:1.08 max_critic_abs_err:2.97 policy_loss:106.81 alpha:0.31 alpha_loss:6.13 q:-109.78 q_target:-109.69 log_pi:-6.87 memory:8.13G gpu_mem_ratio:53.7% gpu_mem:2.15G gpu_mem_this:1.40G gpu_util:30%
