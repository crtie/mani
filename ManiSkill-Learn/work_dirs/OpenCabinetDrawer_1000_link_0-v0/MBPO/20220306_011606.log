OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:07 - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA GeForce GTX 1650
CUDA_HOME: /usr/local/cuda-11.1/bin
NVCC: 
Num of GPUs: 1
GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.9.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.0
OpenCV: 4.5.3
mani_skill_learn: 1.0.0
------------------------------------------------------------

OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:08 - Config:
agent = dict(
    type='MBPO',
    batch_size=1024,
    gamma=0.95,
    update_coeff=0.005,
    alpha=0.2,
    target_update_interval=1,
    automatic_alpha_tuning=True,
    alpha_optim_cfg=dict(type='Adam', lr=0.0003),
    policy_cfg=dict(
        type='ContinuousPolicy',
        policy_head_cfg=dict(
            type='GaussianHead', log_sig_min=-20, log_sig_max=2,
            epsilon=1e-06),
        nn_cfg=dict(
            type='LinearMLP',
            norm_cfg=None,
            mlp_spec=['obs_shape', 256, 256, 256, 'action_shape * 2'],
            bias='auto',
            inactivated_output=True,
            linear_init_cfg=dict(type='xavier_init', gain=1, bias=0)),
        optim_cfg=dict(type='Adam', lr=0.0003)),
    value_cfg=dict(
        type='ContinuousValue',
        num_heads=2,
        nn_cfg=dict(
            type='LinearMLP',
            norm_cfg=None,
            bias='auto',
            mlp_spec=['obs_shape + action_shape', 256, 256, 256, 1],
            inactivated_output=True,
            linear_init_cfg=dict(type='xavier_init', gain=1, bias=0)),
        optim_cfg=dict(type='Adam', lr=0.0003)),
    model_cfg=dict(
        type='Ensemble_model',
        num_heads=3,
        nn_cfg=dict(
            type='LinearMLP',
            norm_cfg=None,
            bias='auto',
            mlp_spec=[
                'obs_shape + action_shape', 256, 256, 256, 'obs_shape + 1'
            ],
            inactivated_output=True,
            linear_init_cfg=dict(type='xavier_init', gain=1, bias=0)),
        optim_cfg=dict(type='Adam', lr=0.003)))
log_level = 'INFO'
train_mfrl_cfg = dict(
    on_policy=False,
    total_steps=1000000,
    warm_steps=4000,
    n_eval=200000,
    n_checkpoint=200000,
    n_steps=8,
    n_updates=4)
rollout_cfg = dict(
    type='BatchRollout',
    use_cost=False,
    reward_only=False,
    num_procs=8,
    with_info=False,
    env_cfg=dict(
        type='gym',
        unwrapped=False,
        reward_type='dense',
        env_name='OpenCabinetDrawer_1000_link_0-v0'))
eval_cfg = dict(
    type='BatchEvaluation',
    num=10,
    num_procs=2,
    use_hidden_state=False,
    start_state=None,
    save_traj=True,
    save_video=True,
    use_log=False,
    env_cfg=dict(
        type='gym',
        unwrapped=False,
        reward_type='dense',
        env_name='OpenCabinetDrawer_1000_link_0-v0'))
env_cfg = dict(
    type='gym',
    unwrapped=False,
    reward_type='dense',
    env_name='OpenCabinetDrawer_1000_link_0-v0')
replay_cfg = dict(type='ReplayMemory', capacity=1000000)
replay_model_cfg = dict(type='ReplayMemory', capacity=1000000)
work_dir = './work_dirs/OpenCabinetDrawer_1000_link_0-v0/MBPO'

OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:08 - Set random seed to 0
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:11 - State shape:75, action shape:Box(-1.0, 1.0, (13,), float32)
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:13 - We do not use distributed training, but we support data parallel in torch
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:13 - MBPO(
  (policy): ContinuousPolicy(
    (backbone): LinearMLP(
      (mlp): Sequential(
        (linear0): Linear(in_features=75, out_features=256, bias=True)
        (act0): ReLU()
        (linear1): Linear(in_features=256, out_features=256, bias=True)
        (act1): ReLU()
        (linear2): Linear(in_features=256, out_features=256, bias=True)
        (act2): ReLU()
        (linear3): Linear(in_features=256, out_features=26, bias=True)
      )
    )
    (policy_head): GaussianHead()
  )
  (critic): ContinuousValue(
    (values): ModuleList(
      (0): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
      (1): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
    )
  )
  (model): Ensemble_model(
    (values): ModuleList(
      (0): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=76, bias=True)
        )
      )
      (1): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=76, bias=True)
        )
      )
      (2): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=76, bias=True)
        )
      )
    )
  )
  (target_critic): ContinuousValue(
    (values): ModuleList(
      (0): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
      (1): LinearMLP(
        (mlp): Sequential(
          (linear0): Linear(in_features=88, out_features=256, bias=True)
          (act0): ReLU()
          (linear1): Linear(in_features=256, out_features=256, bias=True)
          (act1): ReLU()
          (linear2): Linear(in_features=256, out_features=256, bias=True)
          (act2): ReLU()
          (linear3): Linear(in_features=256, out_features=1, bias=True)
        )
      )
    )
  )
)
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:13 - Rollout state dim: (8, 75), action dim: 8
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:22 - Finish 4000 warm-up steps!
OpenCabinetDrawer_1000_link_0-v0 - INFO - 2022-03-06 01:16:36 - 5600/1000000(1%) Passed time:13s ETA:2h24m2s pred loss:0.66 episode_length:200.00 episode_reward:-2675.55 critic_loss:0.40 max_critic_abs_err:2.43 policy_loss:9.75 alpha:0.80 alpha_loss:17.38 q:-16.78 q_target:-16.70 log_pi:-8.83 memory:8.10G gpu_mem_ratio:55.5% gpu_mem:2.22G gpu_mem_this:1.48G gpu_util:36%
